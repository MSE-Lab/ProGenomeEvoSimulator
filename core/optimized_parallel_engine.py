#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„å¹¶è¡Œè¿›åŒ–å¼•æ“
è§£å†³å¹¶è¡Œå¤„ç†æ€§èƒ½ç“¶é¢ˆé—®é¢˜

ä¸»è¦ä¼˜åŒ–ï¼š
1. å‡å°‘è¿›ç¨‹åˆå§‹åŒ–å¼€é”€
2. ä¼˜åŒ–åˆ†å—ç­–ç•¥
3. å‡å°‘è¿›ç¨‹é—´é€šä¿¡
4. é¢„è®¡ç®—å’Œç¼“å­˜ä¼˜åŒ–

Version: 1.1.0
Author: ProGenomeEvoSimulator Team
Date: 2025-09-27
"""

import time
import copy
import multiprocessing as mp
from multiprocessing import Pool, Manager
from typing import Dict, List, Tuple, Optional, Any
import numpy as np
from functools import partial

from core.genome import Genome, Gene
from mechanisms.point_mutation_optimized import OptimizedPointMutationEngine
from mechanisms.horizontal_transfer import HorizontalGeneTransfer
from mechanisms.homologous_recombination import HomologousRecombination
from mechanisms.gene_loss import GeneLossEngine


# å…¨å±€å˜é‡ç”¨äºå·¥ä½œè¿›ç¨‹åˆå§‹åŒ–ï¼ˆé¿å…é‡å¤åˆ›å»ºï¼‰
_worker_engines = None


def init_worker_process(evolution_params: Dict):
    """
    å·¥ä½œè¿›ç¨‹åˆå§‹åŒ–å‡½æ•° - åªåœ¨è¿›ç¨‹å¯åŠ¨æ—¶è°ƒç”¨ä¸€æ¬¡
    é¿å…æ¯æ¬¡ä»»åŠ¡éƒ½é‡æ–°åˆ›å»ºè¿›åŒ–æœºåˆ¶å®ä¾‹
    """
    global _worker_engines
    
    try:
        # åˆ›å»ºè¿›åŒ–æœºåˆ¶å®ä¾‹ï¼ˆæ¯ä¸ªè¿›ç¨‹åªåˆ›å»ºä¸€æ¬¡ï¼‰
        point_mutation = OptimizedPointMutationEngine(
            mutation_rate=evolution_params['mutation_rate'],
            enable_transition_bias=evolution_params.get('enable_transition_bias', True),
            enable_hotspots=evolution_params.get('enable_hotspots', True)
        )
        
        hgt = HorizontalGeneTransfer(evolution_params['hgt_rate'])
        
        recombination = HomologousRecombination(
            evolution_params['recombination_rate'],
            evolution_params['min_similarity_for_recombination']
        )
        
        _worker_engines = {
            'point_mutation': point_mutation,
            'hgt': hgt,
            'recombination': recombination
        }
        
    except Exception as e:
        print(f"âŒ Worker initialization error: {e}")
        _worker_engines = None


def optimized_evolve_genes_chunk(chunk_data: Tuple[List[Gene], int]) -> Tuple[List[Gene], Dict]:
    """
    ä¼˜åŒ–çš„åŸºå› å—è¿›åŒ–å‡½æ•°
    ä½¿ç”¨é¢„åˆå§‹åŒ–çš„è¿›åŒ–æœºåˆ¶å®ä¾‹
    """
    global _worker_engines
    
    genes_chunk, process_id = chunk_data
    
    # æ£€æŸ¥å·¥ä½œè¿›ç¨‹æ˜¯å¦æ­£ç¡®åˆå§‹åŒ–
    if _worker_engines is None:
        return genes_chunk, {
            'process_id': process_id,
            'genes_processed': len(genes_chunk),
            'mutations': 0,
            'hgt_events': 0,
            'recombination_events': 0,
            'processing_time': 0,
            'error': 'Worker not initialized'
        }
    
    # ç»Ÿè®¡ä¿¡æ¯
    chunk_stats = {
        'process_id': process_id,
        'genes_processed': len(genes_chunk),
        'mutations': 0,
        'hgt_events': 0,
        'recombination_events': 0,
        'processing_time': 0
    }
    
    start_time = time.time()
    
    try:
        # åˆ›å»ºä¸´æ—¶åŸºå› ç»„ç”¨äºå¤„ç†è¿™ä¸ªå—
        temp_genome = Genome(genes_chunk)
        
        # ä½¿ç”¨é¢„åˆå§‹åŒ–çš„è¿›åŒ–æœºåˆ¶
        engines = _worker_engines
        
        # åº”ç”¨è¿›åŒ–æœºåˆ¶
        mutations = engines['point_mutation'].apply_mutations(temp_genome, generations=1)
        chunk_stats['mutations'] = mutations
        
        hgt_events = engines['hgt'].apply_hgt(temp_genome, generations=1)
        chunk_stats['hgt_events'] = hgt_events
        
        recombination_events = engines['recombination'].apply_recombination(temp_genome, generations=1)
        chunk_stats['recombination_events'] = recombination_events
        
        # è¿”å›è¿›åŒ–åçš„åŸºå› 
        evolved_genes = temp_genome.genes
        
    except Exception as e:
        print(f"âŒ Error in process {process_id}: {e}")
        chunk_stats['error'] = str(e)
        evolved_genes = genes_chunk  # è¿”å›åŸå§‹åŸºå› 
    
    chunk_stats['processing_time'] = time.time() - start_time
    
    return evolved_genes, chunk_stats


class OptimizedParallelEvolutionEngine:
    """
    ä¼˜åŒ–çš„å¹¶è¡Œè¿›åŒ–å¼•æ“
    è§£å†³åŸæœ‰å¹¶è¡Œå®ç°çš„æ€§èƒ½ç“¶é¢ˆ
    """
    
    def __init__(self, 
                 # åŸºæœ¬è¿›åŒ–å‚æ•°
                 mutation_rate: float = 1e-6,
                 hgt_rate: float = 1e-8,
                 recombination_rate: float = 1e-9,
                 min_similarity_for_recombination: float = 0.85,  # ä¿®æ­£ï¼šæ›´ä¸¥æ ¼çš„é‡ç»„ç›¸ä¼¼åº¦è¦æ±‚
                 
                 # åŸºå› ä¸¢å¤±å‚æ•°
                 enable_gene_loss: bool = True,
                 loss_rate: float = 1e-6,
                 core_gene_protection: float = 0.95,
                 hgt_gene_loss_multiplier: float = 10.0,
                 min_genome_size: int = 1000,
                 min_core_genes: int = 800,
                 optimal_genome_size: int = 3000,
                 
                 # ä¼˜åŒ–çš„å¹¶è¡Œå¤„ç†å‚æ•°
                 enable_parallel: bool = True,
                 num_processes: Optional[int] = None,
                 min_chunk_size: int = 100,  # æœ€å°åˆ†å—å¤§å°
                 max_chunk_size: int = 1000,  # æœ€å¤§åˆ†å—å¤§å°
                 parallel_threshold: int = 500,  # å¯ç”¨å¹¶è¡Œçš„åŸºå› æ•°é˜ˆå€¼
                 
                 # æ€§èƒ½ä¼˜åŒ–å‚æ•°
                 enable_optimization: bool = True):
        """
        åˆå§‹åŒ–ä¼˜åŒ–çš„å¹¶è¡Œè¿›åŒ–å¼•æ“
        """
        
        # å­˜å‚¨é…ç½®å‚æ•°
        self.config = {
            'mutation_rate': mutation_rate,
            'hgt_rate': hgt_rate,
            'recombination_rate': recombination_rate,
            'min_similarity_for_recombination': min_similarity_for_recombination,
            'enable_gene_loss': enable_gene_loss,
            'loss_rate': loss_rate,
            'core_gene_protection': core_gene_protection,
            'hgt_gene_loss_multiplier': hgt_gene_loss_multiplier,
            'min_genome_size': min_genome_size,
            'min_core_genes': min_core_genes,
            'optimal_genome_size': optimal_genome_size,
            'enable_parallel': enable_parallel,
            'num_processes': num_processes or mp.cpu_count(),
            'min_chunk_size': min_chunk_size,
            'max_chunk_size': max_chunk_size,
            'parallel_threshold': parallel_threshold,
            'enable_optimization': enable_optimization
        }
        
        # åˆå§‹åŒ–è¿›åŒ–æœºåˆ¶
        self._initialize_mechanisms()
        
        # è¿›åŒ–å†å²è®°å½•
        self.evolution_history = []
        
        # è¿›ç¨‹æ± ï¼ˆé‡ç”¨ä»¥é¿å…é‡å¤åˆ›å»ºï¼‰
        self._pool = None
        
        # æ‰“å°åˆå§‹åŒ–ä¿¡æ¯
        self._print_initialization_info()
    
    def _initialize_mechanisms(self):
        """åˆå§‹åŒ–æ‰€æœ‰è¿›åŒ–æœºåˆ¶"""
        
        # 1. ç‚¹çªå˜å¼•æ“ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        self.point_mutation = OptimizedPointMutationEngine(
            mutation_rate=self.config['mutation_rate'],
            enable_transition_bias=True,
            enable_hotspots=True
        )
        
        # 2. æ¨ªå‘åŸºå› è½¬ç§»
        self.hgt = HorizontalGeneTransfer(self.config['hgt_rate'])
        
        # 3. åŒæºé‡ç»„
        self.recombination = HomologousRecombination(
            self.config['recombination_rate'],
            self.config['min_similarity_for_recombination']
        )
        
        # 4. åŸºå› ä¸¢å¤±ï¼ˆå¯é€‰ï¼‰
        if self.config['enable_gene_loss']:
            self.gene_loss = GeneLossEngine(
                loss_rate=self.config['loss_rate'],
                core_gene_protection=self.config['core_gene_protection'],
                hgt_gene_loss_multiplier=self.config['hgt_gene_loss_multiplier'],
                min_genome_size=self.config['min_genome_size'],
                min_core_genes=self.config['min_core_genes'],
                optimal_genome_size=self.config['optimal_genome_size']
            )
        else:
            self.gene_loss = None
    
    def _print_initialization_info(self):
        """æ‰“å°åˆå§‹åŒ–ä¿¡æ¯"""
        print(f"ğŸš€ Optimized Parallel Evolution Engine initialized:")
        print(f"   Mechanisms: Point mutations, HGT, Recombination" + 
              (", Gene loss" if self.config['enable_gene_loss'] else ""))
        print(f"   Optimization: {'Enabled' if self.config['enable_optimization'] else 'Disabled'}")
        print(f"   Parallel processing: {'Enabled' if self.config['enable_parallel'] else 'Disabled'}")
        if self.config['enable_parallel']:
            print(f"   Processes: {self.config['num_processes']}")
            print(f"   Chunk size: {self.config['min_chunk_size']}-{self.config['max_chunk_size']} genes")
            print(f"   Parallel threshold: {self.config['parallel_threshold']} genes")
        if self.config['enable_gene_loss']:
            print(f"   Gene loss rate: {self.config['loss_rate']}")
    
    def _should_use_parallel(self, genome: Genome) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨å¹¶è¡Œå¤„ç†"""
        return (self.config['enable_parallel'] and 
                genome.gene_count >= self.config['parallel_threshold'] and
                self.config['num_processes'] > 1)
    
    def _calculate_optimal_chunk_size(self, total_genes: int) -> int:
        """
        è®¡ç®—æœ€ä¼˜çš„åŸºå› åˆ†å—å¤§å°
        ä¼˜åŒ–ç­–ç•¥ï¼šå‡å°‘åˆ†å—æ•°é‡ï¼Œå¢åŠ æ¯å—å¤§å°
        """
        min_size = self.config['min_chunk_size']
        max_size = self.config['max_chunk_size']
        num_processes = self.config['num_processes']
        
        # ç›®æ ‡ï¼šæ¯ä¸ªè¿›ç¨‹å¤„ç†2-4ä¸ªå—
        target_chunks_per_process = 3
        target_total_chunks = num_processes * target_chunks_per_process
        
        # è®¡ç®—ç†æƒ³åˆ†å—å¤§å°
        ideal_chunk_size = max(min_size, total_genes // target_total_chunks)
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        optimal_chunk_size = min(max_size, max(min_size, ideal_chunk_size))
        
        return optimal_chunk_size
    
    def _split_genes_into_chunks(self, genes: List[Gene]) -> List[List[Gene]]:
        """å°†åŸºå› åˆ—è¡¨åˆ†å‰²æˆé€‚åˆå¹¶è¡Œå¤„ç†çš„å—"""
        chunk_size = self._calculate_optimal_chunk_size(len(genes))
        chunks = []
        
        for i in range(0, len(genes), chunk_size):
            chunk = genes[i:i + chunk_size]
            chunks.append(chunk)
        
        return chunks
    
    def _get_or_create_pool(self) -> Pool:
        """è·å–æˆ–åˆ›å»ºè¿›ç¨‹æ± ï¼ˆé‡ç”¨ä»¥æé«˜æ€§èƒ½ï¼‰"""
        if self._pool is None:
            # å‡†å¤‡è¿›åŒ–å‚æ•°
            evolution_params = {
                'mutation_rate': self.config['mutation_rate'],
                'hgt_rate': self.config['hgt_rate'],
                'recombination_rate': self.config['recombination_rate'],
                'min_similarity_for_recombination': self.config['min_similarity_for_recombination'],
                'enable_transition_bias': True,
                'enable_hotspots': True
            }
            
            # åˆ›å»ºè¿›ç¨‹æ± å¹¶åˆå§‹åŒ–å·¥ä½œè¿›ç¨‹
            self._pool = Pool(
                processes=self.config['num_processes'],
                initializer=init_worker_process,
                initargs=(evolution_params,)
            )
        
        return self._pool
    
    def evolve_one_generation_serial(self, genome: Genome) -> Dict:
        """ä¸²è¡Œè¿›åŒ–ä¸€ä»£"""
        generation_stats = {
            'generation': genome.generation + 1,
            'initial_stats': genome.get_statistics(),
            'mutations': 0,
            'hgt_events': 0,
            'recombination_events': 0,
            'genes_lost': 0,
            'processing_mode': 'serial'
        }
        
        # 1. åº”ç”¨ç‚¹çªå˜
        mutations = self.point_mutation.apply_mutations(genome, generations=1)
        generation_stats['mutations'] = mutations
        
        # 2. åº”ç”¨æ¨ªå‘åŸºå› è½¬ç§»
        hgt_events = self.hgt.apply_hgt(genome, generations=1)
        generation_stats['hgt_events'] = hgt_events
        
        # 3. åº”ç”¨åŒæºé‡ç»„
        recombination_events = self.recombination.apply_recombination(genome, generations=1)
        generation_stats['recombination_events'] = recombination_events
        
        # 4. åº”ç”¨åŸºå› ä¸¢å¤±ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.gene_loss:
            genes_lost = self.gene_loss.apply_gene_loss(genome, generations=1)
            generation_stats['genes_lost'] = genes_lost
        
        # æ›´æ–°ä»£æ•°
        genome.generation += 1
        
        # è®°å½•æœ€ç»ˆç»Ÿè®¡
        generation_stats['final_stats'] = genome.get_statistics()
        
        return generation_stats
    
    def evolve_one_generation_parallel(self, genome: Genome) -> Dict:
        """ä¼˜åŒ–çš„å¹¶è¡Œè¿›åŒ–ä¸€ä»£"""
        generation_start_time = time.time()
        
        # åˆ†å‰²åŸºå› åˆ°ä¸åŒçš„å—
        gene_chunks = self._split_genes_into_chunks(genome.genes)
        
        generation_stats = {
            'generation': genome.generation + 1,
            'initial_stats': genome.get_statistics(),
            'total_mutations': 0,
            'total_hgt_events': 0,
            'total_recombination_events': 0,
            'genes_lost': 0,
            'chunks_processed': len(gene_chunks),
            'parallel_processing_time': 0,
            'processing_mode': 'parallel'
        }
        
        parallel_start_time = time.time()
        
        # è·å–è¿›ç¨‹æ± 
        pool = self._get_or_create_pool()
        
        # å‡†å¤‡ä»»åŠ¡æ•°æ®
        chunk_args = [(chunk, i) for i, chunk in enumerate(gene_chunks)]
        
        # å¹¶è¡Œæ‰§è¡Œï¼ˆä½¿ç”¨é¢„åˆå§‹åŒ–çš„å·¥ä½œè¿›ç¨‹ï¼‰
        try:
            results = pool.map(optimized_evolve_genes_chunk, chunk_args)
        except Exception as e:
            print(f"âŒ Parallel processing error: {e}")
            # å›é€€åˆ°ä¸²è¡Œå¤„ç†
            return self.evolve_one_generation_serial(genome)
        
        parallel_end_time = time.time()
        generation_stats['parallel_processing_time'] = parallel_end_time - parallel_start_time
        
        # åˆå¹¶ç»“æœ
        evolved_genes = []
        for evolved_chunk, chunk_stats in results:
            evolved_genes.extend(evolved_chunk)
            generation_stats['total_mutations'] += chunk_stats['mutations']
            generation_stats['total_hgt_events'] += chunk_stats['hgt_events']
            generation_stats['total_recombination_events'] += chunk_stats['recombination_events']
        
        # æ›´æ–°åŸºå› ç»„
        genome.genes = evolved_genes
        genome.total_mutations += generation_stats['total_mutations']
        genome.total_hgt_events += generation_stats['total_hgt_events']
        genome.total_recombination_events += generation_stats['total_recombination_events']
        
        # åº”ç”¨åŸºå› ä¸¢å¤±ï¼ˆåœ¨ä¸»è¿›ç¨‹ä¸­å¤„ç†ï¼‰
        if self.gene_loss:
            genes_lost = self.gene_loss.apply_gene_loss(genome, generations=1)
            generation_stats['genes_lost'] = genes_lost
        
        # æ›´æ–°ä»£æ•°
        genome.generation += 1
        
        # è®°å½•æœ€ç»ˆç»Ÿè®¡
        generation_stats['final_stats'] = genome.get_statistics()
        generation_stats['total_processing_time'] = time.time() - generation_start_time
        
        return generation_stats
    
    def evolve_one_generation(self, genome: Genome) -> Dict:
        """è¿›åŒ–ä¸€ä»£ï¼ˆè‡ªåŠ¨é€‰æ‹©ä¸²è¡Œæˆ–å¹¶è¡Œï¼‰"""
        if self._should_use_parallel(genome):
            return self.evolve_one_generation_parallel(genome)
        else:
            return self.evolve_one_generation_serial(genome)
    
    def evolve_multiple_generations(self, genome: Genome, generations: int, 
                                  show_progress: bool = True) -> List[Dict]:
        """è¿›åŒ–å¤šä»£"""
        history = []
        start_time = time.time()
        
        # ç¡®å®šå¤„ç†æ¨¡å¼
        use_parallel = self._should_use_parallel(genome)
        processing_mode = "OPTIMIZED PARALLEL" if use_parallel else "SERIAL"
        
        if show_progress:
            print(f"ğŸš€ Starting {processing_mode} evolution: {generations:,} generations")
            if use_parallel:
                print(f"   Processes: {self.config['num_processes']}")
                chunk_size = self._calculate_optimal_chunk_size(genome.gene_count)
                estimated_chunks = max(1, genome.gene_count // chunk_size)
                print(f"   Chunk strategy: ~{chunk_size} genes/chunk (~{estimated_chunks} chunks)")
            print("=" * 80)
        
        # ç¡®å®šæ˜¾ç¤ºé¢‘ç‡
        if generations <= 50:
            display_freq = 5
        elif generations <= 100:
            display_freq = 10
        elif generations <= 1000:
            display_freq = 50
        else:
            display_freq = 100
        
        for gen in range(generations):
            gen_start_time = time.time()
            
            # è¿›åŒ–ä¸€ä»£
            gen_stats = self.evolve_one_generation(genome)
            
            gen_end_time = time.time()
            gen_duration = gen_end_time - gen_start_time
            gen_stats['wall_clock_time'] = gen_duration
            
            history.append(gen_stats)
            
            # æ˜¾ç¤ºè¿›åº¦
            if show_progress and ((gen + 1) % display_freq == 0 or gen == 0):
                elapsed_total = time.time() - start_time
                avg_time_per_gen = elapsed_total / (gen + 1)
                remaining_gens = generations - (gen + 1)
                estimated_remaining = remaining_gens * avg_time_per_gen
                
                # è¿›åº¦æ¡
                progress = (gen + 1) / generations
                bar_width = 30
                filled_width = int(bar_width * progress)
                bar = 'â–ˆ' * filled_width + 'â–‘' * (bar_width - filled_width)
                
                # åŸºå› ç»„ä¿¡æ¯
                genome_info = (f"Genes: {genome.gene_count:,} | "
                             f"Events: {genome.total_mutations:,}mut "
                             f"{genome.total_hgt_events:,}HGT "
                             f"{genome.total_recombination_events:,}rec")
                
                # å¹¶è¡Œæ€§èƒ½ä¿¡æ¯
                if use_parallel and 'parallel_processing_time' in gen_stats:
                    parallel_efficiency = (gen_stats['parallel_processing_time'] / 
                                         gen_stats['total_processing_time']) * 100 if gen_stats['total_processing_time'] > 0 else 0
                    parallel_info = f" | Eff: {parallel_efficiency:.1f}%"
                    genome_info += parallel_info
                
                print(f"\r[{bar}] {progress*100:.1f}% | Gen {gen + 1:,}/{generations:,} | "
                      f"{1/avg_time_per_gen:.1f} gen/s | ETA: {estimated_remaining/60:.1f}min | "
                      f"{genome_info}", end="", flush=True)
        
        if show_progress:
            total_time = time.time() - start_time
            print(f"\n\nğŸ‰ {processing_mode} evolution completed!")
            print(f"Total time: {total_time/60:.2f} minutes")
            print(f"Average speed: {generations/total_time:.2f} generations/second")
            
            if use_parallel:
                avg_parallel_efficiency = np.mean([
                    (h['parallel_processing_time'] / h['total_processing_time']) * 100 
                    for h in history if 'parallel_processing_time' in h and h['total_processing_time'] > 0
                ])
                print(f"Average parallel efficiency: {avg_parallel_efficiency:.1f}%")
            
            print("=" * 80)
        
        self.evolution_history.extend(history)
        return history
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self._pool is not None:
            self._pool.close()
            self._pool.join()
            self._pool = None
        print("ğŸ§¹ Parallel resources cleaned up")
    
    def __del__(self):
        """ææ„å‡½æ•° - ç¡®ä¿èµ„æºæ¸…ç†"""
        self.cleanup()