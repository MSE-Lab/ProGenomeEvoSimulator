#!/usr/bin/env python3
"""
Parallel Evolution Engine
ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡ŒåŒ–çš„è¿›åŒ–å¼•æ“ï¼Œä¸“ä¸ºå¤šCPUæœåŠ¡å™¨ç¯å¢ƒä¼˜åŒ–
"""

import time
import copy
import multiprocessing as mp
from multiprocessing import Pool, Manager, Value, Lock
from typing import Dict, List, Tuple, Optional, Any
import numpy as np
from functools import partial
import os

from core.genome import Genome, Gene
from core.evolution_engine_optimized import OptimizedEvolutionEngine
from mechanisms.point_mutation_optimized import OptimizedPointMutationEngine
from mechanisms.horizontal_transfer import HorizontalGeneTransfer
from mechanisms.homologous_recombination import HomologousRecombination


class ParallelEvolutionEngine:
    """å¹¶è¡ŒåŒ–è¿›åŒ–å¼•æ“ - åˆ©ç”¨å¤šCPUæ ¸å¿ƒåŠ é€ŸåŸºå› ç»„è¿›åŒ–æ¨¡æ‹Ÿ"""
    
    def __init__(self, 
                 mutation_rate: float = 1e-9,
                 hgt_rate: float = 0.001,
                 recombination_rate: float = 1e-6,
                 min_similarity_for_recombination: float = 0.7,
                 num_processes: Optional[int] = None,
                 chunk_size: Optional[int] = None,
                 enable_progress_sharing: bool = True):
        """
        åˆå§‹åŒ–å¹¶è¡ŒåŒ–è¿›åŒ–å¼•æ“
        
        Args:
            num_processes: å¹¶è¡Œè¿›ç¨‹æ•°ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨CPUæ ¸å¿ƒæ•°
            chunk_size: åŸºå› åˆ†å—å¤§å°ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨è®¡ç®—
            enable_progress_sharing: æ˜¯å¦å¯ç”¨è¿›ç¨‹é—´è¿›åº¦å…±äº«
        """
        
        # è¿›åŒ–å‚æ•°
        self.mutation_rate = mutation_rate
        self.hgt_rate = hgt_rate
        self.recombination_rate = recombination_rate
        self.min_similarity_for_recombination = min_similarity_for_recombination
        
        # å¹¶è¡ŒåŒ–é…ç½®
        self.num_processes = num_processes or mp.cpu_count()
        self.chunk_size = chunk_size
        self.enable_progress_sharing = enable_progress_sharing
        
        # ç¡®ä¿ä¸è¶…è¿‡ç³»ç»ŸCPUæ ¸å¿ƒæ•°
        max_cores = mp.cpu_count()
        if self.num_processes > max_cores:
            print(f"âš ï¸  Warning: Requested {self.num_processes} processes, but only {max_cores} CPU cores available")
            self.num_processes = max_cores
        
        # è¿›åŒ–å†å²è®°å½•
        self.evolution_history = []
        
        print(f"ğŸš€ Parallel Evolution Engine initialized:")
        print(f"   CPU cores available: {max_cores}")
        print(f"   Processes to use: {self.num_processes}")
        print(f"   Progress sharing: {'Enabled' if enable_progress_sharing else 'Disabled'}")
    
    def _calculate_optimal_chunk_size(self, total_genes: int) -> int:
        """è®¡ç®—æœ€ä¼˜çš„åŸºå› åˆ†å—å¤§å°"""
        if self.chunk_size:
            return self.chunk_size
        
        # åŸºäºåŸºå› æ•°é‡å’Œè¿›ç¨‹æ•°è®¡ç®—æœ€ä¼˜åˆ†å—å¤§å°
        # ç›®æ ‡ï¼šæ¯ä¸ªè¿›ç¨‹å¤„ç†çš„åŸºå› æ•°é‡ç›¸å¯¹å‡è¡¡ï¼Œé¿å…è´Ÿè½½ä¸å‡
        base_chunk_size = max(1, total_genes // (self.num_processes * 4))  # æ¯ä¸ªè¿›ç¨‹4ä¸ªå—
        
        # æ ¹æ®åŸºå› æ•°é‡è°ƒæ•´
        if total_genes < 100:
            return max(1, total_genes // self.num_processes)
        elif total_genes < 1000:
            return min(50, base_chunk_size)
        else:
            return min(200, base_chunk_size)
    
    def _split_genes_into_chunks(self, genes: List[Gene]) -> List[List[Gene]]:
        """å°†åŸºå› åˆ—è¡¨åˆ†å‰²æˆé€‚åˆå¹¶è¡Œå¤„ç†çš„å—"""
        chunk_size = self._calculate_optimal_chunk_size(len(genes))
        chunks = []
        
        for i in range(0, len(genes), chunk_size):
            chunk = genes[i:i + chunk_size]
            chunks.append(chunk)
        
        return chunks
    
    def evolve_genes_chunk_parallel(self, genes_chunk: List[Gene], 
                                  evolution_params: Dict,
                                  shared_progress: Optional[Any] = None,
                                  process_id: int = 0) -> Tuple[List[Gene], Dict]:
        """
        å¹¶è¡Œå¤„ç†åŸºå› å—çš„è¿›åŒ–
        
        Args:
            genes_chunk: è¦å¤„ç†çš„åŸºå› å—
            evolution_params: è¿›åŒ–å‚æ•°
            shared_progress: å…±äº«çš„è¿›åº¦è®¡æ•°å™¨
            process_id: è¿›ç¨‹ID
        
        Returns:
            (evolved_genes, stats): è¿›åŒ–åçš„åŸºå› å’Œç»Ÿè®¡ä¿¡æ¯
        """
        
        # åˆ›å»ºæœ¬åœ°è¿›åŒ–æœºåˆ¶å®ä¾‹ï¼ˆé¿å…è¿›ç¨‹é—´å…±äº«é—®é¢˜ï¼‰
        point_mutation = OptimizedPointMutationEngine(
            mutation_rate=evolution_params['mutation_rate'],
            enable_transition_bias=evolution_params.get('enable_transition_bias', True),
            transition_transversion_ratio=evolution_params.get('transition_transversion_ratio', 2.0),
            enable_hotspots=evolution_params.get('enable_hotspots', True)
        )
        
        hgt = HorizontalGeneTransfer(evolution_params['hgt_rate'])
        recombination = HomologousRecombination(
            evolution_params['recombination_rate'],
            evolution_params['min_similarity_for_recombination']
        )
        
        # ç»Ÿè®¡ä¿¡æ¯
        chunk_stats = {
            'process_id': process_id,
            'genes_processed': len(genes_chunk),
            'mutations': 0,
            'hgt_events': 0,
            'recombination_events': 0,
            'processing_time': 0
        }
        
        start_time = time.time()
        
        # åˆ›å»ºä¸´æ—¶åŸºå› ç»„ç”¨äºå¤„ç†è¿™ä¸ªå—
        temp_genome = Genome(genes_chunk)
        
        # åº”ç”¨è¿›åŒ–æœºåˆ¶
        try:
            # ç‚¹çªå˜
            mutations = point_mutation.apply_mutations(temp_genome, generations=1)
            chunk_stats['mutations'] = mutations
            
            # HGTï¼ˆéœ€è¦å°å¿ƒå¤„ç†ï¼Œé¿å…åŸºå› æ•°é‡å˜åŒ–å¯¼è‡´çš„å¹¶è¡Œé—®é¢˜ï¼‰
            hgt_events = hgt.apply_hgt(temp_genome, generations=1)
            chunk_stats['hgt_events'] = hgt_events
            
            # åŒæºé‡ç»„
            recombination_events = recombination.apply_recombination(temp_genome, generations=1)
            chunk_stats['recombination_events'] = recombination_events
            
        except Exception as e:
            print(f"âŒ Error in process {process_id}: {e}")
            chunk_stats['error'] = str(e)
        
        chunk_stats['processing_time'] = time.time() - start_time
        
        # æ›´æ–°å…±äº«è¿›åº¦è®¡æ•°å™¨
        if shared_progress is not None:
            with shared_progress.get_lock():
                shared_progress.value += len(genes_chunk)
        
        return temp_genome.genes, chunk_stats
    
    def evolve_one_generation_parallel(self, genome: Genome) -> Dict:
        """ä½¿ç”¨å¹¶è¡Œå¤„ç†è¿›åŒ–ä¸€ä»£"""
        
        generation_start_time = time.time()
        
        # å‡†å¤‡è¿›åŒ–å‚æ•°
        evolution_params = {
            'mutation_rate': self.mutation_rate,
            'hgt_rate': self.hgt_rate,
            'recombination_rate': self.recombination_rate,
            'min_similarity_for_recombination': self.min_similarity_for_recombination,
            'enable_transition_bias': True,
            'transition_transversion_ratio': 2.0,
            'enable_hotspots': True
        }
        
        # åˆ†å‰²åŸºå› åˆ°ä¸åŒçš„å—
        gene_chunks = self._split_genes_into_chunks(genome.genes)
        
        generation_stats = {
            'generation': genome.generation + 1,
            'initial_stats': genome.get_statistics(),
            'total_mutations': 0,
            'total_hgt_events': 0,
            'total_recombination_events': 0,
            'chunks_processed': len(gene_chunks),
            'parallel_processing_time': 0,
            'chunk_stats': []
        }
        
        # è®¾ç½®å…±äº«è¿›åº¦è®¡æ•°å™¨
        if self.enable_progress_sharing:
            manager = Manager()
            shared_progress = manager.Value('i', 0)
        else:
            shared_progress = None
        
        parallel_start_time = time.time()
        
        # å¹¶è¡Œå¤„ç†æ‰€æœ‰åŸºå› å—
        with Pool(processes=self.num_processes) as pool:
            # åˆ›å»ºéƒ¨åˆ†å‡½æ•°ï¼Œå›ºå®ševolution_paramså’Œshared_progress
            process_func = partial(
                evolve_genes_chunk_worker,
                evolution_params=evolution_params,
                shared_progress=shared_progress
            )
            
            # ä¸ºæ¯ä¸ªå—æ·»åŠ è¿›ç¨‹ID
            chunk_args = [(chunk, i) for i, chunk in enumerate(gene_chunks)]
            
            # å¹¶è¡Œæ‰§è¡Œ
            results = pool.map(process_func, chunk_args)
        
        parallel_end_time = time.time()
        generation_stats['parallel_processing_time'] = parallel_end_time - parallel_start_time
        
        # åˆå¹¶ç»“æœ
        evolved_genes = []
        for evolved_chunk, chunk_stats in results:
            evolved_genes.extend(evolved_chunk)
            generation_stats['total_mutations'] += chunk_stats['mutations']
            generation_stats['total_hgt_events'] += chunk_stats['hgt_events']
            generation_stats['total_recombination_events'] += chunk_stats['recombination_events']
            generation_stats['chunk_stats'].append(chunk_stats)
        
        # æ›´æ–°åŸºå› ç»„
        genome.genes = evolved_genes
        genome.generation += 1
        genome.total_mutations += generation_stats['total_mutations']
        genome.total_hgt_events += generation_stats['total_hgt_events']
        genome.total_recombination_events += generation_stats['total_recombination_events']
        
        # è®°å½•æœ€ç»ˆç»Ÿè®¡
        generation_stats['final_stats'] = genome.get_statistics()
        generation_stats['total_processing_time'] = time.time() - generation_start_time
        
        return generation_stats
    
    def evolve_multiple_generations_parallel(self, genome: Genome, generations: int, 
                                           show_progress: bool = True) -> List[Dict]:
        """å¹¶è¡Œè¿›åŒ–å¤šä»£"""
        
        history = []
        start_time = time.time()
        
        if show_progress:
            # æ ¹æ®ä»£æ•°ç¡®å®šæ˜¾ç¤ºé¢‘ç‡
            if generations <= 50:
                display_freq = 5
            elif generations <= 100:
                display_freq = 10
            elif generations <= 1000:
                display_freq = 50
            else:
                display_freq = 100
            
            print(f"ğŸš€ Starting PARALLEL evolution simulation: {generations:,} generations")
            print(f"   Parallel processes: {self.num_processes}")
            print(f"   Progress updates every {display_freq} generation(s)")
            print("=" * 80)
        else:
            display_freq = max(1, generations // 10)
        
        for gen in range(generations):
            gen_start_time = time.time()
            
            # å¹¶è¡Œè¿›åŒ–ä¸€ä»£
            gen_stats = self.evolve_one_generation_parallel(genome)
            
            gen_end_time = time.time()
            gen_duration = gen_end_time - gen_start_time
            gen_stats['wall_clock_time'] = gen_duration
            
            history.append(gen_stats)
            
            # æ˜¾ç¤ºè¿›åº¦
            if show_progress and ((gen + 1) % display_freq == 0 or gen == 0):
                elapsed_total = time.time() - start_time
                avg_time_per_gen = elapsed_total / (gen + 1)
                remaining_gens = generations - (gen + 1)
                estimated_remaining = remaining_gens * avg_time_per_gen
                
                # è®¡ç®—å¹¶è¡Œæ•ˆç‡
                parallel_time = gen_stats['parallel_processing_time']
                total_time = gen_stats['total_processing_time']
                parallel_efficiency = (parallel_time / total_time) * 100 if total_time > 0 else 0
                
                # è¿›åº¦æ¡
                progress = (gen + 1) / generations
                bar_width = 30
                filled_width = int(bar_width * progress)
                bar = 'â–ˆ' * filled_width + 'â–‘' * (bar_width - filled_width)
                
                # åŸºå› ç»„ä¿¡æ¯
                genome_info = (f"Genes: {genome.gene_count:,} | "
                             f"Events: {genome.total_mutations:,}mut "
                             f"{genome.total_hgt_events:,}HGT "
                             f"{genome.total_recombination_events:,}rec")
                
                # å¹¶è¡Œæ€§èƒ½ä¿¡æ¯
                parallel_info = (f"Parallel: {parallel_efficiency:.1f}% | "
                               f"Chunks: {gen_stats['chunks_processed']} | "
                               f"Processes: {self.num_processes}")
                
                print(f"\r[{bar}] {progress*100:.1f}% | Gen {gen + 1:,}/{generations:,} | "
                      f"{1/avg_time_per_gen:.1f} gen/s | ETA: {estimated_remaining/60:.1f}min | "
                      f"{genome_info} | {parallel_info}", end="", flush=True)
        
        if show_progress:
            total_time = time.time() - start_time
            print(f"\n\nğŸ‰ PARALLEL evolution completed!")
            print(f"Total time: {total_time/60:.2f} minutes ({total_time/3600:.2f} hours)")
            print(f"Average speed: {generations/total_time:.2f} generations/second")
            
            # å¹¶è¡Œæ€§èƒ½åˆ†æ
            avg_parallel_efficiency = np.mean([
                (h['parallel_processing_time'] / h['total_processing_time']) * 100 
                for h in history if h['total_processing_time'] > 0
            ])
            
            print(f"Parallel efficiency: {avg_parallel_efficiency:.1f}%")
            print(f"Processes used: {self.num_processes}/{mp.cpu_count()}")
            print("=" * 80)
        
        self.evolution_history.extend(history)
        return history
    
    def simulate_evolution_parallel(self, 
                                  initial_genome: Genome, 
                                  generations: int,
                                  save_snapshots: bool = True,
                                  snapshot_interval: int = 100) -> Tuple[Genome, List[Dict]]:
        """å®Œæ•´çš„å¹¶è¡Œè¿›åŒ–æ¨¡æ‹Ÿ"""
        
        print("ğŸš€ PARALLEL PROKARYOTIC GENOME EVOLUTION SIMULATION")
        print("=" * 80)
        print(f"ğŸ“Š Initial genome: {initial_genome.gene_count:,} genes, {initial_genome.size:,} bp")
        print(f"ğŸ¯ Target generations: {generations:,}")
        print(f"ğŸ“¸ Snapshots: {'Enabled' if save_snapshots else 'Disabled'} (interval: {snapshot_interval})")
        print(f"âš¡ Parallel processing: {self.num_processes} processes")
        print(f"ğŸ§¬ Evolution mechanisms: Parallel point mutations, HGT, Homologous recombination")
        print("=" * 80)
        
        # åˆ›å»ºåŸºå› ç»„å‰¯æœ¬
        evolving_genome = initial_genome.copy()
        simulation_start_time = time.time()
        
        # è®°å½•åˆå§‹çŠ¶æ€
        snapshots = []
        if save_snapshots:
            initial_summary = self._get_evolution_summary(evolving_genome)
            initial_summary['snapshot_generation'] = 0
            snapshots.append(initial_summary)
        
        # å¹¶è¡Œè¿›åŒ–è¿‡ç¨‹
        evolution_history = self.evolve_multiple_generations_parallel(
            evolving_genome, generations, show_progress=True
        )
        
        # ä¿å­˜å¿«ç…§
        if save_snapshots:
            print(f"ğŸ“¸ Saving snapshots every {snapshot_interval} generations...")
            for i in range(0, len(evolution_history), snapshot_interval):
                if i < len(evolution_history):
                    snapshot = self._get_evolution_summary(evolving_genome)
                    snapshot['snapshot_generation'] = evolution_history[i]['generation']
                    snapshots.append(snapshot)
        
        # æœ€ç»ˆæ€»ç»“
        total_simulation_time = time.time() - simulation_start_time
        
        print(f"\nğŸ‰ PARALLEL SIMULATION COMPLETED!")
        print(f"ğŸ§¬ Final genome: {evolving_genome.gene_count:,} genes, {evolving_genome.size:,} bp")
        print(f"ğŸ“ˆ Changes: {evolving_genome.size - initial_genome.size:+,} bp, "
              f"{evolving_genome.gene_count - initial_genome.gene_count:+,} genes")
        print(f"âš¡ Parallel performance: {self.num_processes} processes, "
              f"{generations/total_simulation_time:.2f} gen/s")
        
        return evolving_genome, snapshots
    
    def _get_evolution_summary(self, genome: Genome) -> Dict:
        """è·å–è¿›åŒ–æ€»ç»“"""
        return {
            'genome_stats': genome.get_statistics(),
            'parallel_info': {
                'processes_used': self.num_processes,
                'parallel_processing': True,
                'cpu_cores_available': mp.cpu_count()
            }
        }
    
    def get_parallel_performance_analysis(self) -> Dict:
        """åˆ†æå¹¶è¡Œæ€§èƒ½"""
        if not self.evolution_history:
            return {'error': 'No evolution history available'}
        
        parallel_times = [h['parallel_processing_time'] for h in self.evolution_history]
        total_times = [h['total_processing_time'] for h in self.evolution_history]
        
        parallel_efficiencies = [
            (p_time / t_time) * 100 if t_time > 0 else 0
            for p_time, t_time in zip(parallel_times, total_times)
        ]
        
        chunks_per_generation = [h['chunks_processed'] for h in self.evolution_history]
        
        return {
            'avg_parallel_efficiency': np.mean(parallel_efficiencies),
            'min_parallel_efficiency': np.min(parallel_efficiencies),
            'max_parallel_efficiency': np.max(parallel_efficiencies),
            'avg_parallel_time': np.mean(parallel_times),
            'avg_total_time': np.mean(total_times),
            'avg_chunks_per_generation': np.mean(chunks_per_generation),
            'processes_used': self.num_processes,
            'cpu_cores_available': mp.cpu_count(),
            'theoretical_speedup': self.num_processes,
            'actual_speedup': np.mean(parallel_efficiencies) / 100 * self.num_processes
        }


def evolve_genes_chunk_worker(chunk_args: Tuple[List[Gene], int], 
                            evolution_params: Dict,
                            shared_progress: Optional[Any] = None) -> Tuple[List[Gene], Dict]:
    """
    å·¥ä½œè¿›ç¨‹å‡½æ•°ï¼šå¤„ç†åŸºå› å—çš„è¿›åŒ–
    è¿™ä¸ªå‡½æ•°éœ€è¦åœ¨æ¨¡å—çº§åˆ«å®šä¹‰ä»¥æ”¯æŒmultiprocessing
    """
    genes_chunk, process_id = chunk_args
    
    # ç›´æ¥åœ¨å·¥ä½œè¿›ç¨‹ä¸­å¤„ç†ï¼Œé¿å…å¾ªç¯å¯¼å…¥
    from mechanisms.point_mutation_optimized import OptimizedPointMutationEngine
    from mechanisms.horizontal_transfer import HorizontalGeneTransfer
    from mechanisms.homologous_recombination import HomologousRecombination
    from core.genome import Genome
    
    # åˆ›å»ºæœ¬åœ°è¿›åŒ–æœºåˆ¶å®ä¾‹
    point_mutation = OptimizedPointMutationEngine(
        mutation_rate=evolution_params['mutation_rate'],
        enable_transition_bias=evolution_params.get('enable_transition_bias', True),
        transition_transversion_ratio=evolution_params.get('transition_transversion_ratio', 2.0),
        enable_hotspots=evolution_params.get('enable_hotspots', True)
    )
    
    hgt = HorizontalGeneTransfer(evolution_params['hgt_rate'])
    recombination = HomologousRecombination(
        evolution_params['recombination_rate'],
        evolution_params['min_similarity_for_recombination']
    )
    
    # ç»Ÿè®¡ä¿¡æ¯
    chunk_stats = {
        'process_id': process_id,
        'genes_processed': len(genes_chunk),
        'mutations': 0,
        'hgt_events': 0,
        'recombination_events': 0,
        'processing_time': 0
    }
    
    import time
    start_time = time.time()
    
    # åˆ›å»ºä¸´æ—¶åŸºå› ç»„ç”¨äºå¤„ç†è¿™ä¸ªå—
    temp_genome = Genome(genes_chunk)
    
    # åº”ç”¨è¿›åŒ–æœºåˆ¶
    try:
        # ç‚¹çªå˜
        mutations = point_mutation.apply_mutations(temp_genome, generations=1)
        chunk_stats['mutations'] = mutations
        
        # HGTï¼ˆéœ€è¦å°å¿ƒå¤„ç†ï¼Œé¿å…åŸºå› æ•°é‡å˜åŒ–å¯¼è‡´çš„å¹¶è¡Œé—®é¢˜ï¼‰
        hgt_events = hgt.apply_hgt(temp_genome, generations=1)
        chunk_stats['hgt_events'] = hgt_events
        
        # åŒæºé‡ç»„
        recombination_events = recombination.apply_recombination(temp_genome, generations=1)
        chunk_stats['recombination_events'] = recombination_events
        
    except Exception as e:
        print(f"âŒ Error in process {process_id}: {e}")
        chunk_stats['error'] = str(e)
    
    chunk_stats['processing_time'] = time.time() - start_time
    
    # æ›´æ–°å…±äº«è¿›åº¦è®¡æ•°å™¨
    if shared_progress is not None:
        try:
            with shared_progress.get_lock():
                shared_progress.value += len(genes_chunk)
        except:
            pass  # å¿½ç•¥å…±äº«è¿›åº¦æ›´æ–°é”™è¯¯
    
    return temp_genome.genes, chunk_stats