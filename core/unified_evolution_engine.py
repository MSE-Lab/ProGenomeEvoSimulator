#!/usr/bin/env python3
"""
Unified Evolution Engine
ç»Ÿä¸€çš„è¿›åŒ–å¼•æ“ - é›†æˆæ‰€æœ‰åŠŸèƒ½çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ
åŒ…å«ï¼šä¼˜åŒ–ç®—æ³•ã€å¹¶è¡Œå¤„ç†ã€åŸºå› ä¸¢å¤±ã€ä¿å®ˆæ€§åˆ†æç­‰æ‰€æœ‰åŠŸèƒ½

Version: 1.0.0
Author: ProGenomeEvoSimulator Team
Date: 2025-09-27
"""

__version__ = "1.0.0"
__author__ = "ProGenomeEvoSimulator Team"
__date__ = "2025-09-27"

import time
import copy
import multiprocessing as mp
from multiprocessing import Pool, Manager
from typing import Dict, List, Tuple, Optional, Any
import numpy as np
from functools import partial

from core.genome import Genome, Gene
from mechanisms.point_mutation_optimized import OptimizedPointMutationEngine
from mechanisms.horizontal_transfer import HorizontalGeneTransfer
from mechanisms.homologous_recombination import HomologousRecombination
from mechanisms.gene_loss import GeneLossEngine


class UnifiedEvolutionEngine:
    """
    ç»Ÿä¸€è¿›åŒ–å¼•æ“ - é›†æˆæ‰€æœ‰è¿›åŒ–æœºåˆ¶å’Œä¼˜åŒ–åŠŸèƒ½
    
    åŠŸèƒ½ç‰¹æ€§ï¼š
    - ç‚¹çªå˜ï¼ˆä¼˜åŒ–ç®—æ³•ï¼‰
    - æ¨ªå‘åŸºå› è½¬ç§»
    - åŒæºé‡ç»„
    - åŸºå› ä¸¢å¤±
    - å¹¶è¡Œå¤„ç†
    - æ€§èƒ½ä¼˜åŒ–
    - è¯¦ç»†ç»Ÿè®¡
    """
    
    def __init__(self, 
                 # åŸºæœ¬è¿›åŒ–å‚æ•°
                 mutation_rate: float = 1e-6,
                 hgt_rate: float = 1e-8,
                 recombination_rate: float = 1e-9,
                 min_similarity_for_recombination: float = 0.7,
                 
                 # åŸºå› ä¸¢å¤±å‚æ•°
                 enable_gene_loss: bool = True,
                 loss_rate: float = 1e-6,
                 core_gene_protection: float = 0.95,
                 hgt_gene_loss_multiplier: float = 10.0,
                 min_genome_size: int = 1000,
                 min_core_genes: int = 800,
                 optimal_genome_size: int = 3000,
                 
                 # å¹¶è¡Œå¤„ç†å‚æ•°
                 enable_parallel: bool = True,
                 num_processes: Optional[int] = None,
                 chunk_size: Optional[int] = None,
                 parallel_threshold: int = 500,  # åŸºå› æ•°è¶…è¿‡æ­¤å€¼æ—¶å¯ç”¨å¹¶è¡Œ
                 
                 # æ€§èƒ½ä¼˜åŒ–å‚æ•°
                 enable_optimization: bool = True,
                 enable_progress_sharing: bool = True):
        """
        åˆå§‹åŒ–ç»Ÿä¸€è¿›åŒ–å¼•æ“
        
        Args:
            # åŸºæœ¬è¿›åŒ–å‚æ•°
            mutation_rate: ç‚¹çªå˜ç‡
            hgt_rate: æ¨ªå‘åŸºå› è½¬ç§»ç‡
            recombination_rate: åŒæºé‡ç»„ç‡
            min_similarity_for_recombination: é‡ç»„æ‰€éœ€æœ€å°ç›¸ä¼¼åº¦
            
            # åŸºå› ä¸¢å¤±å‚æ•°
            enable_gene_loss: æ˜¯å¦å¯ç”¨åŸºå› ä¸¢å¤±
            loss_rate: åŸºå› ä¸¢å¤±ç‡
            core_gene_protection: æ ¸å¿ƒåŸºå› ä¿æŠ¤ç³»æ•°
            hgt_gene_loss_multiplier: HGTåŸºå› ä¸¢å¤±å€æ•°
            min_genome_size: æœ€å°åŸºå› ç»„å¤§å°
            min_core_genes: æœ€å°æ ¸å¿ƒåŸºå› æ•°
            optimal_genome_size: æœ€ä¼˜åŸºå› ç»„å¤§å°
            
            # å¹¶è¡Œå¤„ç†å‚æ•°
            enable_parallel: æ˜¯å¦å¯ç”¨å¹¶è¡Œå¤„ç†
            num_processes: å¹¶è¡Œè¿›ç¨‹æ•°
            chunk_size: åŸºå› åˆ†å—å¤§å°
            parallel_threshold: å¯ç”¨å¹¶è¡Œçš„åŸºå› æ•°é˜ˆå€¼
            
            # æ€§èƒ½ä¼˜åŒ–å‚æ•°
            enable_optimization: æ˜¯å¦å¯ç”¨æ€§èƒ½ä¼˜åŒ–
            enable_progress_sharing: æ˜¯å¦å¯ç”¨è¿›åº¦å…±äº«
        """
        
        # å­˜å‚¨é…ç½®å‚æ•°
        self.config = {
            'mutation_rate': mutation_rate,
            'hgt_rate': hgt_rate,
            'recombination_rate': recombination_rate,
            'min_similarity_for_recombination': min_similarity_for_recombination,
            'enable_gene_loss': enable_gene_loss,
            'loss_rate': loss_rate,
            'core_gene_protection': core_gene_protection,
            'hgt_gene_loss_multiplier': hgt_gene_loss_multiplier,
            'min_genome_size': min_genome_size,
            'min_core_genes': min_core_genes,
            'optimal_genome_size': optimal_genome_size,
            'enable_parallel': enable_parallel,
            'num_processes': num_processes or mp.cpu_count(),
            'chunk_size': chunk_size,
            'parallel_threshold': parallel_threshold,
            'enable_optimization': enable_optimization,
            'enable_progress_sharing': enable_progress_sharing
        }
        
        # åˆå§‹åŒ–è¿›åŒ–æœºåˆ¶
        self._initialize_mechanisms()
        
        # è¿›åŒ–å†å²è®°å½•
        self.evolution_history = []
        
        # æ‰“å°åˆå§‹åŒ–ä¿¡æ¯
        self._print_initialization_info()
    
    def _initialize_mechanisms(self):
        """åˆå§‹åŒ–æ‰€æœ‰è¿›åŒ–æœºåˆ¶"""
        
        # 1. ç‚¹çªå˜å¼•æ“ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        if self.config['enable_optimization']:
            self.point_mutation = OptimizedPointMutationEngine(
                mutation_rate=self.config['mutation_rate'],
                enable_transition_bias=True,
                enable_hotspots=True
            )
        else:
            # å¦‚æœéœ€è¦ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ åŸºç¡€ç‰ˆæœ¬
            self.point_mutation = OptimizedPointMutationEngine(
                mutation_rate=self.config['mutation_rate']
            )
        
        # 2. æ¨ªå‘åŸºå› è½¬ç§»
        self.hgt = HorizontalGeneTransfer(self.config['hgt_rate'])
        
        # 3. åŒæºé‡ç»„
        self.recombination = HomologousRecombination(
            self.config['recombination_rate'],
            self.config['min_similarity_for_recombination']
        )
        
        # 4. åŸºå› ä¸¢å¤±ï¼ˆå¯é€‰ï¼‰
        if self.config['enable_gene_loss']:
            self.gene_loss = GeneLossEngine(
                loss_rate=self.config['loss_rate'],
                core_gene_protection=self.config['core_gene_protection'],
                hgt_gene_loss_multiplier=self.config['hgt_gene_loss_multiplier'],
                min_genome_size=self.config['min_genome_size'],
                min_core_genes=self.config['min_core_genes'],
                optimal_genome_size=self.config['optimal_genome_size']
            )
        else:
            self.gene_loss = None
    
    def _print_initialization_info(self):
        """æ‰“å°åˆå§‹åŒ–ä¿¡æ¯"""
        print(f"ğŸ§¬ Unified Evolution Engine initialized:")
        print(f"   Mechanisms: Point mutations, HGT, Recombination" + 
              (", Gene loss" if self.config['enable_gene_loss'] else ""))
        print(f"   Optimization: {'Enabled' if self.config['enable_optimization'] else 'Disabled'}")
        print(f"   Parallel processing: {'Enabled' if self.config['enable_parallel'] else 'Disabled'}")
        if self.config['enable_parallel']:
            print(f"   Processes: {self.config['num_processes']}")
            print(f"   Parallel threshold: {self.config['parallel_threshold']} genes")
        if self.config['enable_gene_loss']:
            print(f"   Gene loss rate: {self.config['loss_rate']}")
            print(f"   Core protection: {self.config['core_gene_protection']*100:.1f}%")
    
    def _should_use_parallel(self, genome: Genome) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨å¹¶è¡Œå¤„ç†"""
        return (self.config['enable_parallel'] and 
                genome.gene_count >= self.config['parallel_threshold'] and
                self.config['num_processes'] > 1)
    
    def _calculate_optimal_chunk_size(self, total_genes: int) -> int:
        """è®¡ç®—æœ€ä¼˜çš„åŸºå› åˆ†å—å¤§å°"""
        if self.config['chunk_size']:
            return self.config['chunk_size']
        
        # è‡ªåŠ¨è®¡ç®—æœ€ä¼˜åˆ†å—å¤§å°
        base_chunk_size = max(1, total_genes // (self.config['num_processes'] * 4))
        
        if total_genes < 100:
            return max(1, total_genes // self.config['num_processes'])
        elif total_genes < 1000:
            return min(50, base_chunk_size)
        else:
            return min(200, base_chunk_size)
    
    def _split_genes_into_chunks(self, genes: List[Gene]) -> List[List[Gene]]:
        """å°†åŸºå› åˆ—è¡¨åˆ†å‰²æˆé€‚åˆå¹¶è¡Œå¤„ç†çš„å—"""
        chunk_size = self._calculate_optimal_chunk_size(len(genes))
        chunks = []
        
        for i in range(0, len(genes), chunk_size):
            chunk = genes[i:i + chunk_size]
            chunks.append(chunk)
        
        return chunks
    
    def evolve_one_generation_serial(self, genome: Genome) -> Dict:
        """ä¸²è¡Œè¿›åŒ–ä¸€ä»£"""
        generation_stats = {
            'generation': genome.generation + 1,
            'initial_stats': genome.get_statistics(),
            'mutations': 0,
            'hgt_events': 0,
            'recombination_events': 0,
            'genes_lost': 0,
            'processing_mode': 'serial'
        }
        
        # 1. åº”ç”¨ç‚¹çªå˜
        mutations = self.point_mutation.apply_mutations(genome, generations=1)
        generation_stats['mutations'] = mutations
        
        # 2. åº”ç”¨æ¨ªå‘åŸºå› è½¬ç§»
        hgt_events = self.hgt.apply_hgt(genome, generations=1)
        generation_stats['hgt_events'] = hgt_events
        
        # 3. åº”ç”¨åŒæºé‡ç»„
        recombination_events = self.recombination.apply_recombination(genome, generations=1)
        generation_stats['recombination_events'] = recombination_events
        
        # 4. åº”ç”¨åŸºå› ä¸¢å¤±ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.gene_loss:
            genes_lost = self.gene_loss.apply_gene_loss(genome, generations=1)
            generation_stats['genes_lost'] = genes_lost
        
        # æ›´æ–°ä»£æ•°
        genome.generation += 1
        
        # è®°å½•æœ€ç»ˆç»Ÿè®¡
        generation_stats['final_stats'] = genome.get_statistics()
        
        return generation_stats
    
    def evolve_one_generation_parallel(self, genome: Genome) -> Dict:
        """å¹¶è¡Œè¿›åŒ–ä¸€ä»£"""
        generation_start_time = time.time()
        
        # å‡†å¤‡è¿›åŒ–å‚æ•°
        evolution_params = {
            'mutation_rate': self.config['mutation_rate'],
            'hgt_rate': self.config['hgt_rate'],
            'recombination_rate': self.config['recombination_rate'],
            'min_similarity_for_recombination': self.config['min_similarity_for_recombination'],
            'enable_transition_bias': True,
            'enable_hotspots': True
        }
        
        # åˆ†å‰²åŸºå› åˆ°ä¸åŒçš„å—
        gene_chunks = self._split_genes_into_chunks(genome.genes)
        
        generation_stats = {
            'generation': genome.generation + 1,
            'initial_stats': genome.get_statistics(),
            'total_mutations': 0,
            'total_hgt_events': 0,
            'total_recombination_events': 0,
            'genes_lost': 0,
            'chunks_processed': len(gene_chunks),
            'parallel_processing_time': 0,
            'processing_mode': 'parallel'
        }
        
        # è®¾ç½®å…±äº«è¿›åº¦è®¡æ•°å™¨
        if self.config['enable_progress_sharing']:
            manager = Manager()
            shared_progress = manager.Value('i', 0)
        else:
            shared_progress = None
        
        parallel_start_time = time.time()
        
        # å¹¶è¡Œå¤„ç†æ‰€æœ‰åŸºå› å—
        with Pool(processes=self.config['num_processes']) as pool:
            # åˆ›å»ºéƒ¨åˆ†å‡½æ•°
            process_func = partial(
                evolve_genes_chunk_worker,
                evolution_params=evolution_params,
                shared_progress=shared_progress
            )
            
            # ä¸ºæ¯ä¸ªå—æ·»åŠ è¿›ç¨‹ID
            chunk_args = [(chunk, i) for i, chunk in enumerate(gene_chunks)]
            
            # å¹¶è¡Œæ‰§è¡Œ
            results = pool.map(process_func, chunk_args)
        
        parallel_end_time = time.time()
        generation_stats['parallel_processing_time'] = parallel_end_time - parallel_start_time
        
        # åˆå¹¶ç»“æœ
        evolved_genes = []
        for evolved_chunk, chunk_stats in results:
            evolved_genes.extend(evolved_chunk)
            generation_stats['total_mutations'] += chunk_stats['mutations']
            generation_stats['total_hgt_events'] += chunk_stats['hgt_events']
            generation_stats['total_recombination_events'] += chunk_stats['recombination_events']
        
        # æ›´æ–°åŸºå› ç»„
        genome.genes = evolved_genes
        genome.total_mutations += generation_stats['total_mutations']
        genome.total_hgt_events += generation_stats['total_hgt_events']
        genome.total_recombination_events += generation_stats['total_recombination_events']
        
        # åº”ç”¨åŸºå› ä¸¢å¤±ï¼ˆåœ¨ä¸»è¿›ç¨‹ä¸­å¤„ç†ï¼Œé¿å…å¹¶è¡Œå¤æ‚æ€§ï¼‰
        if self.gene_loss:
            genes_lost = self.gene_loss.apply_gene_loss(genome, generations=1)
            generation_stats['genes_lost'] = genes_lost
        
        # æ›´æ–°ä»£æ•°
        genome.generation += 1
        
        # è®°å½•æœ€ç»ˆç»Ÿè®¡
        generation_stats['final_stats'] = genome.get_statistics()
        generation_stats['total_processing_time'] = time.time() - generation_start_time
        
        return generation_stats
    
    def evolve_one_generation(self, genome: Genome) -> Dict:
        """è¿›åŒ–ä¸€ä»£ï¼ˆè‡ªåŠ¨é€‰æ‹©ä¸²è¡Œæˆ–å¹¶è¡Œï¼‰"""
        if self._should_use_parallel(genome):
            return self.evolve_one_generation_parallel(genome)
        else:
            return self.evolve_one_generation_serial(genome)
    
    def evolve_multiple_generations(self, genome: Genome, generations: int, 
                                  show_progress: bool = True) -> List[Dict]:
        """è¿›åŒ–å¤šä»£"""
        history = []
        start_time = time.time()
        
        # ç¡®å®šå¤„ç†æ¨¡å¼
        use_parallel = self._should_use_parallel(genome)
        processing_mode = "PARALLEL" if use_parallel else "SERIAL"
        
        if show_progress:
            # ç¡®å®šæ˜¾ç¤ºé¢‘ç‡
            if generations <= 50:
                display_freq = 5
            elif generations <= 100:
                display_freq = 10
            elif generations <= 1000:
                display_freq = 50
            else:
                display_freq = 100
            
            print(f"Starting {processing_mode} evolution simulation: {generations:,} generations")
            if use_parallel:
                print(f"Parallel processes: {self.config['num_processes']}")
            print(f"Progress updates every {display_freq} generation(s)")
            print("=" * 80)
        else:
            display_freq = max(1, generations // 10)
        
        for gen in range(generations):
            gen_start_time = time.time()
            
            # è¿›åŒ–ä¸€ä»£
            gen_stats = self.evolve_one_generation(genome)
            
            gen_end_time = time.time()
            gen_duration = gen_end_time - gen_start_time
            gen_stats['wall_clock_time'] = gen_duration
            
            history.append(gen_stats)
            
            # æ˜¾ç¤ºè¿›åº¦
            if show_progress and ((gen + 1) % display_freq == 0 or gen == 0):
                elapsed_total = time.time() - start_time
                avg_time_per_gen = elapsed_total / (gen + 1)
                remaining_gens = generations - (gen + 1)
                estimated_remaining = remaining_gens * avg_time_per_gen
                
                # è¿›åº¦æ¡
                progress = (gen + 1) / generations
                bar_width = 30
                filled_width = int(bar_width * progress)
                bar = 'â–ˆ' * filled_width + 'â–‘' * (bar_width - filled_width)
                
                # åŸºå› ç»„ä¿¡æ¯
                genome_info = (f"Genes: {genome.gene_count:,} | "
                             f"Events: {genome.total_mutations:,}mut "
                             f"{genome.total_hgt_events:,}HGT "
                             f"{genome.total_recombination_events:,}rec")
                
                # åŸºå› ä¸¢å¤±ä¿¡æ¯
                if self.gene_loss:
                    loss_stats = self.gene_loss.get_loss_statistics(genome)
                    loss_info = f" {loss_stats['total_genes_lost']:,}lost"
                    genome_info += loss_info
                
                # å¹¶è¡Œæ€§èƒ½ä¿¡æ¯
                if use_parallel and 'parallel_processing_time' in gen_stats:
                    parallel_efficiency = (gen_stats['parallel_processing_time'] / 
                                         gen_stats['total_processing_time']) * 100 if gen_stats['total_processing_time'] > 0 else 0
                    parallel_info = f" | Parallel: {parallel_efficiency:.1f}%"
                    genome_info += parallel_info
                
                print(f"\r[{bar}] {progress*100:.1f}% | Gen {gen + 1:,}/{generations:,} | "
                      f"{1/avg_time_per_gen:.1f} gen/s | ETA: {estimated_remaining/60:.1f}min | "
                      f"{genome_info}", end="", flush=True)
        
        if show_progress:
            total_time = time.time() - start_time
            print(f"\n\nğŸš€ {processing_mode} evolution completed!")
            print(f"Total time: {total_time/60:.2f} minutes ({total_time/3600:.2f} hours)")
            print(f"Average speed: {generations/total_time:.2f} generations/second")
            
            # æ˜¾ç¤ºç»Ÿè®¡æ‘˜è¦
            if self.gene_loss:
                loss_stats = self.gene_loss.get_loss_statistics(genome)
                print(f"Gene loss: {loss_stats['total_genes_lost']} genes lost "
                      f"({loss_stats['avg_total_loss_per_generation']:.3f}/gen)")
            
            if use_parallel:
                avg_parallel_efficiency = np.mean([
                    (h['parallel_processing_time'] / h['total_processing_time']) * 100 
                    for h in history if 'parallel_processing_time' in h and h['total_processing_time'] > 0
                ])
                print(f"Parallel efficiency: {avg_parallel_efficiency:.1f}%")
            
            print("=" * 80)
        
        self.evolution_history.extend(history)
        return history
    
    def simulate_evolution(self, 
                          initial_genome: Genome, 
                          generations: int,
                          save_snapshots: bool = True,
                          snapshot_interval: int = 100) -> Tuple[Genome, List[Dict]]:
        """å®Œæ•´çš„è¿›åŒ–æ¨¡æ‹Ÿ"""
        
        print("ğŸ§¬ UNIFIED PROKARYOTIC GENOME EVOLUTION SIMULATION")
        print("=" * 80)
        print(f"ğŸ“Š Initial genome: {initial_genome.gene_count:,} genes, {initial_genome.size:,} bp")
        print(f"ğŸ¯ Target generations: {generations:,}")
        print(f"ğŸ“¸ Snapshots: {'Enabled' if save_snapshots else 'Disabled'} (interval: {snapshot_interval})")
        
        # æ˜¾ç¤ºå¯ç”¨çš„åŠŸèƒ½
        features = []
        if self.config['enable_optimization']:
            features.append("Optimized algorithms")
        if self.config['enable_parallel']:
            features.append(f"Parallel processing ({self.config['num_processes']} cores)")
        if self.config['enable_gene_loss']:
            features.append("Gene loss")
        
        print(f"âš¡ Features: {', '.join(features)}")
        print(f"ğŸ§¬ Mechanisms: Point mutations, HGT, Homologous recombination" + 
              (", Gene loss" if self.config['enable_gene_loss'] else ""))
        print("=" * 80)
        
        # åˆ›å»ºåŸºå› ç»„å‰¯æœ¬
        evolving_genome = initial_genome.copy()
        simulation_start_time = time.time()
        
        # è®°å½•åˆå§‹çŠ¶æ€
        snapshots = []
        if save_snapshots:
            initial_summary = self.get_evolution_summary(evolving_genome)
            initial_summary['snapshot_generation'] = 0
            snapshots.append(initial_summary)
        
        # è¿›åŒ–è¿‡ç¨‹
        evolution_history = self.evolve_multiple_generations(
            evolving_genome, generations, show_progress=True
        )
        
        # ä¿å­˜å¿«ç…§
        if save_snapshots:
            print(f"ğŸ“¸ Saving snapshots every {snapshot_interval} generations...")
            for i in range(0, len(evolution_history), snapshot_interval):
                if i < len(evolution_history):
                    snapshot = self.get_evolution_summary(evolving_genome)
                    snapshot['snapshot_generation'] = evolution_history[i]['generation']
                    snapshots.append(snapshot)
        
        # æœ€ç»ˆæ€»ç»“
        total_simulation_time = time.time() - simulation_start_time
        
        print(f"\nğŸ‰ UNIFIED SIMULATION COMPLETED!")
        print(f"ğŸ§¬ Final genome: {evolving_genome.gene_count:,} genes, {evolving_genome.size:,} bp")
        print(f"ğŸ“ˆ Changes: {evolving_genome.size - initial_genome.size:+,} bp, "
              f"{evolving_genome.gene_count - initial_genome.gene_count:+,} genes")
        
        # æ€§èƒ½æ€»ç»“
        use_parallel = self._should_use_parallel(initial_genome)
        if use_parallel:
            print(f"âš¡ Performance: {self.config['num_processes']} processes, "
                  f"{generations/total_simulation_time:.2f} gen/s")
        else:
            print(f"âš¡ Performance: Serial processing, {generations/total_simulation_time:.2f} gen/s")
        
        return evolving_genome, snapshots
    
    def get_evolution_summary(self, genome: Genome) -> Dict:
        """è·å–è¿›åŒ–æ€»ç»“"""
        summary = {
            'genome_stats': genome.get_statistics(),
            'mutation_stats': self.point_mutation.get_mutation_statistics(genome),
            'hgt_stats': self.hgt.get_hgt_statistics(genome),
            'recombination_stats': self.recombination.get_recombination_statistics(genome),
            'engine_config': self.config.copy()
        }
        
        # æ·»åŠ åŸºå› ä¸¢å¤±ç»Ÿè®¡
        if self.gene_loss:
            summary['gene_loss_stats'] = self.gene_loss.get_loss_statistics(genome)
            summary['gene_loss_patterns'] = self.gene_loss.analyze_loss_patterns(genome)
        
        return summary
    
    def get_performance_analysis(self) -> Dict:
        """è·å–æ€§èƒ½åˆ†æ"""
        if not self.evolution_history:
            return {'error': 'No evolution history available'}
        
        analysis = {
            'total_generations': len(self.evolution_history),
            'processing_modes': {},
            'average_times': {},
            'engine_config': self.config.copy()
        }
        
        # åˆ†æå¤„ç†æ¨¡å¼
        serial_gens = [h for h in self.evolution_history if h.get('processing_mode') == 'serial']
        parallel_gens = [h for h in self.evolution_history if h.get('processing_mode') == 'parallel']
        
        analysis['processing_modes'] = {
            'serial_generations': len(serial_gens),
            'parallel_generations': len(parallel_gens)
        }
        
        # è®¡ç®—å¹³å‡æ—¶é—´
        if serial_gens:
            analysis['average_times']['serial'] = np.mean([h['wall_clock_time'] for h in serial_gens])
        
        if parallel_gens:
            analysis['average_times']['parallel'] = np.mean([h['wall_clock_time'] for h in parallel_gens])
            
            # å¹¶è¡Œæ•ˆç‡åˆ†æ
            parallel_efficiencies = []
            for h in parallel_gens:
                if 'parallel_processing_time' in h and h['total_processing_time'] > 0:
                    eff = (h['parallel_processing_time'] / h['total_processing_time']) * 100
                    parallel_efficiencies.append(eff)
            
            if parallel_efficiencies:
                analysis['parallel_efficiency'] = {
                    'average': np.mean(parallel_efficiencies),
                    'min': np.min(parallel_efficiencies),
                    'max': np.max(parallel_efficiencies)
                }
        
        return analysis
    
    def clear_caches(self):
        """æ¸…ç†æ‰€æœ‰ç¼“å­˜"""
        if hasattr(self.point_mutation, 'clear_cache'):
            self.point_mutation.clear_cache()
        print("ğŸ§¹ Caches cleared for memory optimization")


def evolve_genes_chunk_worker(chunk_args: Tuple[List[Gene], int], 
                            evolution_params: Dict,
                            shared_progress: Optional[Any] = None) -> Tuple[List[Gene], Dict]:
    """
    å·¥ä½œè¿›ç¨‹å‡½æ•°ï¼šå¤„ç†åŸºå› å—çš„è¿›åŒ–
    """
    genes_chunk, process_id = chunk_args
    
    # ç›´æ¥åœ¨å·¥ä½œè¿›ç¨‹ä¸­å¤„ç†
    from mechanisms.point_mutation_optimized import OptimizedPointMutationEngine
    from mechanisms.horizontal_transfer import HorizontalGeneTransfer
    from mechanisms.homologous_recombination import HomologousRecombination
    from core.genome import Genome
    
    # åˆ›å»ºæœ¬åœ°è¿›åŒ–æœºåˆ¶å®ä¾‹
    point_mutation = OptimizedPointMutationEngine(
        mutation_rate=evolution_params['mutation_rate'],
        enable_transition_bias=evolution_params.get('enable_transition_bias', True),
        enable_hotspots=evolution_params.get('enable_hotspots', True)
    )
    
    hgt = HorizontalGeneTransfer(evolution_params['hgt_rate'])
    recombination = HomologousRecombination(
        evolution_params['recombination_rate'],
        evolution_params['min_similarity_for_recombination']
    )
    
    # ç»Ÿè®¡ä¿¡æ¯
    chunk_stats = {
        'process_id': process_id,
        'genes_processed': len(genes_chunk),
        'mutations': 0,
        'hgt_events': 0,
        'recombination_events': 0,
        'processing_time': 0
    }
    
    import time
    start_time = time.time()
    
    # åˆ›å»ºä¸´æ—¶åŸºå› ç»„ç”¨äºå¤„ç†è¿™ä¸ªå—
    temp_genome = Genome(genes_chunk)
    
    # åº”ç”¨è¿›åŒ–æœºåˆ¶
    try:
        # ç‚¹çªå˜
        mutations = point_mutation.apply_mutations(temp_genome, generations=1)
        chunk_stats['mutations'] = mutations
        
        # HGT
        hgt_events = hgt.apply_hgt(temp_genome, generations=1)
        chunk_stats['hgt_events'] = hgt_events
        
        # åŒæºé‡ç»„
        recombination_events = recombination.apply_recombination(temp_genome, generations=1)
        chunk_stats['recombination_events'] = recombination_events
        
    except Exception as e:
        print(f"âŒ Error in process {process_id}: {e}")
        chunk_stats['error'] = str(e)
    
    chunk_stats['processing_time'] = time.time() - start_time
    
    # æ›´æ–°å…±äº«è¿›åº¦è®¡æ•°å™¨
    if shared_progress is not None:
        try:
            with shared_progress.get_lock():
                shared_progress.value += len(genes_chunk)
        except:
            pass  # å¿½ç•¥å…±äº«è¿›åº¦æ›´æ–°é”™è¯¯
    
    return temp_genome.genes, chunk_stats